{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for generating Train directory structure\n",
    "new_path = Path(str('Data/Train/'))\n",
    "new_path.mkdir(parents = True, exist_ok = True)\n",
    "new_path.joinpath('0').mkdir(parents = True, exist_ok = True)\n",
    "new_path.joinpath('1').mkdir(parents = True, exist_ok = True)\n",
    "new_path.joinpath('2').mkdir(parents = True, exist_ok = True)\n",
    "new_path.joinpath('3').mkdir(parents = True, exist_ok = True)\n",
    "new_path.joinpath('4').mkdir(parents = True, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for generating Train directory structure\n",
    "new_path = Path(str('Data/Valid/'))\n",
    "new_path.mkdir(parents = True, exist_ok = True)\n",
    "new_path.joinpath('0').mkdir(parents = True, exist_ok = True)\n",
    "new_path.joinpath('1').mkdir(parents = True, exist_ok = True)\n",
    "new_path.joinpath('2').mkdir(parents = True, exist_ok = True)\n",
    "new_path.joinpath('3').mkdir(parents = True, exist_ok = True)\n",
    "new_path.joinpath('4').mkdir(parents = True, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for generating Test directory structure\n",
    "new_path = Path(str('Data/Test/'))\n",
    "new_path.mkdir(parents = True, exist_ok = True)\n",
    "new_path.joinpath('0').mkdir(parents = True, exist_ok = True)\n",
    "new_path.joinpath('1').mkdir(parents = True, exist_ok = True)\n",
    "new_path.joinpath('2').mkdir(parents = True, exist_ok = True)\n",
    "new_path.joinpath('3').mkdir(parents = True, exist_ok = True)\n",
    "new_path.joinpath('4').mkdir(parents = True, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KrishnaS\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "#read the data file\n",
    "df = pd.read_csv(\"mitbih_train.csv\",header=None)\n",
    "#save the png files in their appropriate folders\n",
    "for i in range(5):\n",
    "    #since the last col represents label\n",
    "    x=df.loc[df[187]==i].values.tolist()\n",
    "    count=0\n",
    "    for j in range(int(len(x)*0.8)):\n",
    "        fig = plt.figure()\n",
    "        #remove all the border lines\n",
    "        figure = plt.gca()\n",
    "        x_axis = figure. axes. get_xaxis()\n",
    "        x_axis. set_visible(False)\n",
    "        y_axis = figure. axes. get_yaxis()\n",
    "        y_axis. set_visible(False)\n",
    "        plt.plot(x[j][0:-1])\n",
    "        plt.savefig('Data/Train/'+str(i)+'/'+str(count)+'.png',bbox_inches='tight',pad_inches = 0)\n",
    "        count=count+1\n",
    "    count=0\n",
    "    for k in range(int(len(x)*0.8),len(x)):\n",
    "        fig = plt.figure()\n",
    "        #remove all the border lines\n",
    "        figure = plt.gca()\n",
    "        x_axis = figure. axes. get_xaxis()\n",
    "        x_axis. set_visible(False)\n",
    "        y_axis = figure. axes. get_yaxis()\n",
    "        y_axis. set_visible(False)\n",
    "        plt.plot(x[j][0:-1])\n",
    "        plt.savefig('Data/Valid/'+str(i)+'/'+str(count)+'.png',bbox_inches='tight',pad_inches = 0)\n",
    "        count=count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the data file\n",
    "df = pd.read_csv(\"mitbih_test.csv\",header=None)\n",
    "#save the png files in their appropriate folders\n",
    "for i in range(5):\n",
    "    #since the last col represents label\n",
    "    x=df.loc[df[187]==i].values.tolist()\n",
    "    count=0\n",
    "    for j in range(len(x)):\n",
    "        fig = plt.figure()\n",
    "        #remove all the border lines\n",
    "        figure = plt.gca()\n",
    "        x_axis = figure. axes. get_xaxis()\n",
    "        x_axis. set_visible(False)\n",
    "        y_axis = figure. axes. get_yaxis()\n",
    "        y_axis. set_visible(False)\n",
    "        plt.plot(x[j][0:-1])\n",
    "        plt.savefig('Data/Test/'+str(i)+'/'+str(count)+'.png',bbox_inches='tight',pad_inches = 0)\n",
    "        count=count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for classification\n",
    "# Imports here\n",
    "import torch\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from collections import OrderedDict\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'Data'\n",
    "train_dir = '/Train'\n",
    "valid_dir = data_dir + '/Valid'\n",
    "test_dir = data_dir + '/Test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms for the training data and testing data\n",
    "train_transforms = transforms.Compose([transforms.Resize(256),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                           [0.229, 0.224, 0.225])])\n",
    "\n",
    "\n",
    "valid_transforms = transforms.Compose([transforms.Resize(256),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                           [0.229, 0.224, 0.225])])\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.Resize(256),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                           [0.229, 0.224, 0.225])])\n",
    "\n",
    "\n",
    "# Pass transforms in here, then run the next cell to see how the transforms look\n",
    "train_data = datasets.ImageFolder(train_dir, transform=train_transforms)\n",
    "valid_data = datasets.ImageFolder(valid_dir, transform=valid_transforms)\n",
    "test_data = datasets.ImageFolder(test_dir, transform=test_transforms)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=75, shuffle=True)\n",
    "validloader = torch.utils.data.DataLoader(valid_data, batch_size=75)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.vgg16(pretrained=True)\n",
    "model.name = \"vgg16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "classifier = nn.Sequential(OrderedDict([\n",
    "                          ('fc1', nn.Linear(25088, 4096, bias=True)),\n",
    "                          ('relu1', nn.ReLU()),\n",
    "                          ('dropout1', nn.Dropout(p=0.5)),\n",
    "                          ('fc2', nn.Linear(4096, 5, bias=True)),\n",
    "                          ('output', nn.LogSoftmax(dim=1))\n",
    "                          ]))\n",
    "    \n",
    "model.classifier = classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)\n",
    "epochs = 200\n",
    "print_every = 10\n",
    "steps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, testloader, criterion):\n",
    "    test_loss = 0\n",
    "    accuracy = 0\n",
    "    \n",
    "    for ii, (inputs, labels) in enumerate(testloader):\n",
    "        \n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        output = model.forward(inputs)\n",
    "        test_loss += criterion(output, labels).item()\n",
    "        \n",
    "        ps = torch.exp(output)\n",
    "        equality = (labels.data == ps.max(dim=1)[1])\n",
    "        accuracy += equality.type(torch.FloatTensor).mean()\n",
    "    \n",
    "    return test_loss, accuracy\n",
    "print(\"Training process initializing .....\\n\")\n",
    "\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    model.train() # Technically not necessary, setting this for good measure\n",
    "    \n",
    "    for ii, (inputs, labels) in enumerate(trainloader):\n",
    "        steps += 1\n",
    "        \n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward and backward passes\n",
    "        outputs = model.forward(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if steps % print_every == 0:\n",
    "            model.eval()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                valid_loss, accuracy = validation(model, validloader, criterion)\n",
    "            \n",
    "            print(\"Epoch: {}/{} | \".format(e+1, epochs),\n",
    "                  \"Training Loss: {:.4f} | \".format(running_loss/print_every),\n",
    "                  \"Validation Loss: {:.4f} | \".format(valid_loss/len(testloader)),\n",
    "                  \"Validation Accuracy: {:.4f}\".format(accuracy/len(testloader)))\n",
    "            \n",
    "            running_loss = 0\n",
    "            model.train()\n",
    "\n",
    "print(\"\\nTraining process is now complete!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for testing\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0) \n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy achieved by the network on test images is: %d%%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to save the check point\n",
    "model.class_to_idx = train_data.class_to_idx\n",
    "checkpoint = {'architecture': model.name,\n",
    "             'classifier': model.classifier,\n",
    "             'class_to_idx': model.class_to_idx,\n",
    "             'state_dict': model.state_dict()}\n",
    "\n",
    "torch.save(checkpoint, 'my_checkpoint.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
